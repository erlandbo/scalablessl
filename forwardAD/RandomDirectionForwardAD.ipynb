{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-14T11:22:49.115763560Z",
     "start_time": "2023-09-14T11:22:49.070229340Z"
    }
   },
   "outputs": [],
   "source": [
    "from VisionTransformer import ViT\n",
    "import functorch as ft\n",
    "import torch\n",
    "import torch.func as fc\n",
    "from functools import partial\n",
    "import copy \n",
    "\n",
    "model = ViT(num_classes=10, imgsize=32, patch_dim=4, num_layers=7, d_model=256, nhead=4, d_ff_ratio=4, dropout=0.1, activation=\"gelu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def ad_func(params, buffers, names, model, x, y):\n",
    "    #h, z = model(x)\n",
    "    #loss = F.cross_entropy(z, y)\n",
    "    # x = torch.cat([xi, xj], dim=0)\n",
    "    #h, z = model.forward(x)\n",
    "    z = fc.functional_call(model, ({k: v for k, v in zip(names, params)}, buffers), (x,))\n",
    "    # ((2N, g) @ (g, 2N)) / (2N,1) @ (1,2N) -> (2N, 2N) / (2N,2N)\n",
    "    sim_matrix = (z @ z.T) / (z.norm(p=2, dim=1, keepdim=True) @ z.norm(p=2, dim=1, keepdim=True).T)\n",
    "    mask = torch.eye(z.shape[0], dtype=torch.bool, device=z.device)\n",
    "    pos_mask = mask.roll(shifts=sim_matrix.shape[0]//2, dims=1).bool()  # find pos-pair N away\n",
    "    pos = torch.exp(sim_matrix[pos_mask] / 0.1)\n",
    "    neg = torch.exp(sim_matrix.masked_fill(mask, value=float(\"-inf\")) / 0.1)\n",
    "    loss = -torch.log(pos / torch.sum(neg))\n",
    "    #loss = - (sim_matrix[pos_mask] / self.hparams.temp / 2) + (torch.logsumexp(sim_matrix.masked_fill(mask, value=float(\"-inf\")) / self.hparams.temp, dim=1) / 2)\n",
    "    # Find the rank for the positive pair\n",
    "    sim_matrix = torch.cat([sim_matrix[pos_mask].unsqueeze(1), sim_matrix.masked_fill(pos_mask,float(\"-inf\"))], dim=1)\n",
    "    pos_pair_pos = torch.argsort(sim_matrix, descending=True, dim=1).argmin(dim=1)\n",
    "    top1 = torch.mean((pos_pair_pos == 0).float())\n",
    "    top5 = torch.mean((pos_pair_pos < 5).float())\n",
    "    mean_pos = torch.mean(pos_pair_pos.float())\n",
    "    return torch.mean(loss)# , top1, top5, mean_pos"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T11:22:49.115981351Z",
     "start_time": "2023-09-14T11:22:49.112535887Z"
    }
   },
   "id": "3ed0ce12c6b8488"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "named_buffers = dict(model.named_buffers())\n",
    "named_params = dict(model.named_parameters())\n",
    "names = named_params.keys()\n",
    "params = named_params.values()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T11:22:49.116128190Z",
     "start_time": "2023-09-14T11:22:49.112815509Z"
    }
   },
   "id": "c396c84e9f513a2a"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "x = torch.rand(32, 3, 32, 32)\n",
    "y = torch.rand(32, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T11:22:49.138394217Z",
     "start_time": "2023-09-14T11:22:49.114413015Z"
    }
   },
   "id": "b3b6ca1ea0d940b"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "v_params = tuple([torch.randn_like(param) for param in params])\n",
    "v_params_copy = copy.deepcopy(v_params)\n",
    "foo = partial(\n",
    "    ad_func,\n",
    "    model=model,\n",
    "    names=names,\n",
    "    buffers=named_buffers,\n",
    "    x=x,\n",
    "    y=y\n",
    ")\n",
    "loss, jvp = fc.jvp(foo, (tuple(params),), (v_params,))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T11:22:49.457259031Z",
     "start_time": "2023-09-14T11:22:49.119224038Z"
    }
   },
   "id": "230e58b3b99cbf4f"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(-18.8820, grad_fn=<MeanBackward0>)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jvp"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T11:22:49.457624670Z",
     "start_time": "2023-09-14T11:22:49.456309579Z"
    }
   },
   "id": "2d8f57418200c6e1"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[ 6.0109e-01, -2.9706e-01, -4.9550e-02, -1.0207e+00, -4.9993e-01,\n          -3.2764e-01, -1.5874e-01, -4.6128e-01,  1.8962e-01,  8.0452e-01,\n          -9.9625e-01,  1.6541e+00,  1.2493e+00,  1.1574e+00,  1.0616e-02,\n           5.1207e-01,  8.1531e-01,  9.6493e-01,  9.8747e-01, -1.3913e-01,\n           1.4757e+00,  2.2006e+00,  7.9197e-01, -9.0837e-01, -3.2935e-01,\n           8.4876e-02,  7.5794e-01,  7.0846e-02, -1.2059e+00, -2.1368e-01,\n          -8.5498e-01, -8.4946e-01,  8.4499e-01,  9.0548e-01,  2.7240e-01,\n           4.9713e-02, -7.2316e-01,  1.1908e+00,  6.7316e-01,  6.0828e-03,\n           2.2433e+00,  1.2006e+00,  1.6620e-01, -1.3031e-01, -6.9910e-01,\n           1.7291e-01, -2.4626e+00, -8.2512e-01, -8.6691e-01, -2.0017e-01,\n           4.7458e-03, -7.5629e-03, -3.9518e-01,  1.1264e+00, -1.0212e+00,\n          -6.7782e-01,  2.4335e-01, -3.6254e-01,  6.8250e-01,  2.5501e-01,\n           1.9431e+00,  1.2812e+00,  4.4676e-02,  2.1638e+00,  5.2783e-01,\n          -1.6409e-01,  1.0866e-01,  3.2308e-01, -1.7139e+00, -5.4739e-01,\n           7.0157e-01,  8.2565e-02, -3.9144e-01,  7.0799e-01,  3.0520e-01,\n           7.5039e-02,  3.8735e-01, -2.5960e-01, -6.0024e-02, -4.0060e-01,\n          -1.2899e+00, -9.9413e-02, -7.8091e-01, -6.2799e-01,  6.0608e-01,\n          -6.3493e-01, -9.5667e-01,  9.2155e-01,  1.4358e+00,  1.3041e+00,\n           8.1558e-01,  2.0860e+00,  6.4861e-02, -4.8857e-01,  8.8257e-01,\n           2.0764e+00,  1.4132e-01,  4.5681e-01,  1.9414e+00,  4.4682e-01,\n          -1.4781e+00,  2.5105e+00,  1.1856e+00, -1.1977e+00,  1.6317e+00,\n           7.4671e-01,  1.2342e-01,  1.0197e+00,  1.7998e+00,  5.3037e-01,\n          -1.0540e-01, -2.6396e-01,  6.1388e-01, -4.2376e-01, -1.3451e+00,\n          -9.1446e-01, -1.5889e+00, -8.2707e-02, -1.3819e+00,  5.9192e-01,\n          -1.8910e-01, -6.9006e-01,  6.3916e-02,  1.5917e+00,  1.5063e+00,\n          -1.4346e-01,  9.3654e-01,  5.8749e-01,  1.3091e+00,  4.5574e-01,\n          -3.9714e-01,  1.3104e+00, -8.1506e-01,  1.0658e+00, -1.1377e+00,\n           1.8703e+00,  1.2708e+00,  3.6864e-01, -1.8905e+00,  4.2245e-01,\n           4.6888e-01,  1.2758e+00, -1.7814e+00,  6.6113e-01,  2.6134e-01,\n          -1.2300e+00, -2.1603e+00,  1.0582e+00,  4.1926e-01, -7.2142e-01,\n          -9.8758e-01,  6.9888e-01,  6.8524e-01,  1.2618e-01, -1.8691e+00,\n          -5.8062e-01, -3.3167e-01,  5.8523e-01, -7.3792e-01,  1.0367e+00,\n          -5.8117e-01,  2.5505e-02,  7.2671e-01,  7.1110e-01, -8.5173e-01,\n           1.1588e-01,  8.2157e-01, -7.6356e-01, -5.7012e-01,  7.4228e-01,\n          -1.0957e-01, -7.8942e-01,  1.2171e+00,  4.7394e-01,  1.1898e-03,\n          -8.5576e-02,  1.1057e+00, -1.7267e+00, -5.4828e-01,  4.2142e-01,\n          -7.5305e-01,  2.1526e+00, -6.1693e-01, -1.1649e+00, -3.8232e-01,\n          -1.0995e+00, -1.0407e+00, -2.5101e-01,  1.3194e+00, -1.6697e+00,\n          -3.9872e-03,  3.0718e-02, -5.9977e-01,  2.2992e+00, -1.0907e+00,\n           1.1479e+00, -7.7103e-01,  9.8158e-02, -5.7739e-01, -1.1942e+00,\n           6.9596e-03,  4.1720e-01,  1.7137e+00, -3.9770e-01,  1.2371e+00,\n           5.6724e-01, -1.1029e+00,  1.7321e+00,  6.5467e-01,  7.7453e-01,\n           5.3699e-01, -1.3516e+00,  6.8296e-01,  3.6229e-01,  8.4285e-01,\n          -5.8586e-01, -1.5874e+00,  1.8012e-02,  5.8686e-01, -1.0139e+00,\n          -4.3004e-01, -3.7665e-01,  1.1583e+00,  9.9212e-01,  1.5220e-01,\n           4.8366e-01, -1.1884e+00,  1.9379e-01,  3.8179e-01, -1.4715e-01,\n          -1.4216e+00, -9.4558e-01,  9.6159e-01,  2.0268e-01, -1.0932e-01,\n          -4.2179e-01,  5.6611e-01,  6.7223e-01, -1.8395e-01, -4.1644e-01,\n          -5.2046e-01,  5.0133e-01, -1.1957e+00, -7.6513e-01, -6.9634e-01,\n           2.5548e+00,  4.5309e-01, -1.1715e+00,  2.8849e-01,  1.2261e+00,\n          -2.8057e+00, -1.1381e+00, -7.2171e-01,  5.2807e-01, -1.6767e+00,\n          -1.0698e+00]]])"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_params[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T11:23:16.534972764Z",
     "start_time": "2023-09-14T11:23:16.528065828Z"
    }
   },
   "id": "5a1725c02346f89b"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(256)"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(v_params[0] == v_params_copy[0]).sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T11:23:54.464903376Z",
     "start_time": "2023-09-14T11:23:54.422602195Z"
    }
   },
   "id": "139961c5cc2e9cc5"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "for v, p in zip(v_params, params):\n",
    "    p.grad = v * jvp"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T11:22:49.539766548Z",
     "start_time": "2023-09-14T11:22:49.524393762Z"
    }
   },
   "id": "41992104444a26f7"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ViT' object has no attribute 'embed.convembed.weight'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 9\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m fwAD\u001B[38;5;241m.\u001B[39mdual_level():\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m name, p \u001B[38;5;129;01min\u001B[39;00m params\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m----> 9\u001B[0m         \u001B[38;5;28mdelattr\u001B[39m(model, name)\n\u001B[1;32m     10\u001B[0m         \u001B[38;5;28msetattr\u001B[39m(model, name, fwAD\u001B[38;5;241m.\u001B[39mmake_dual(p, tangents[name]))\n\u001B[1;32m     12\u001B[0m     out \u001B[38;5;241m=\u001B[39m model(\u001B[38;5;28minput\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/scalablessl/lib/python3.11/site-packages/torch/nn/modules/module.py:1685\u001B[0m, in \u001B[0;36mModule.__delattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1683\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_modules[name]\n\u001B[1;32m   1684\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1685\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__delattr__\u001B[39m(name)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'ViT' object has no attribute 'embed.convembed.weight'"
     ]
    }
   ],
   "source": [
    "import torch.autograd.forward_ad as fwAD\n",
    "\n",
    "input = x\n",
    "params = {name: p for name, p in model.named_parameters()}\n",
    "tangents = {name: torch.rand_like(p) for name, p in params.items()}\n",
    "\n",
    "with fwAD.dual_level():\n",
    "    for name, p in params.items():\n",
    "        delattr(model, name)\n",
    "        setattr(model, name, fwAD.make_dual(p, tangents[name]))\n",
    "\n",
    "    out = model(input)\n",
    "    jvp = fwAD.unpack_dual(out).tangent"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T11:22:49.614142658Z",
     "start_time": "2023-09-14T11:22:49.526180985Z"
    }
   },
   "id": "498ab2e487598c26"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.func import functional_call\n",
    "\n",
    "# We need a fresh module because the functional call requires the\n",
    "# the model to have parameters registered.\n",
    "\n",
    "dual_params = {}\n",
    "with fwAD.dual_level():\n",
    "    for name, p in params.items():\n",
    "        # Using the same ``tangents`` from the above section\n",
    "        dual_params[name] = fwAD.make_dual(p, tangents[name])\n",
    "    out = functional_call(model, dual_params, input)\n",
    "    jvp2 = fwAD.unpack_dual(out).tangent\n",
    "\n",
    "# Check our results\n",
    "#assert torch.allclose(jvp, jvp2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-14T11:22:49.568603253Z"
    }
   },
   "id": "1f3f1c7b65dc1f0a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "jvp2.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-14T11:22:49.569426680Z"
    }
   },
   "id": "c88a43f4d0f41094"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
